{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab19c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 74)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, 74, 100)      3098000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_0 (LSTM)               [(None, 74, 200),    240800      ['encoder_embedding[0][0]']      \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_1 (LSTM)               [(None, 74, 200),    320800      ['encoder_0[0][0]',              \n",
      "                                 (None, 200),                     'encoder_0[0][1]',              \n",
      "                                 (None, 200)]                     'encoder_0[0][2]']              \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 100)    1354500     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_2 (LSTM)               [(None, 74, 200),    320800      ['encoder_1[0][0]',              \n",
      "                                 (None, 200),                     'encoder_1[0][1]',              \n",
      "                                 (None, 200)]                     'encoder_1[0][2]']              \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 200),  240800      ['decoder_embedding[0][0]',      \n",
      "                                 (None, 200),                     'encoder_2[0][1]',              \n",
      "                                 (None, 200)]                     'encoder_2[0][2]']              \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, None, 200)    0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'encoder_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 400)    0           ['attention[0][0]',              \n",
      "                                                                  'decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 13545)  5431545     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,007,245\n",
      "Trainable params: 9,652,745\n",
      "Non-trainable params: 1,354,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import the dependencies and load the model\n",
    "\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import spacy\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from seq2seq import Seq2Seq\n",
    "\n",
    "model = load_model(\"s2s.h5\")\n",
    "spacy_model = spacy.load('en_core_web_md')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688d323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizers\n",
    "with open(\"xtk.pkl\",\"rb\") as f:\n",
    "    xtk = pickle.load(f)\n",
    "    \n",
    "with open(\"ytk.pkl\",\"rb\") as f:\n",
    "    ytk = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d2f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_input_seq(text):\n",
    "    text = text.lower().split()\n",
    "    tokens = [contractions.fix(t) for t in text]\n",
    "    tokens = spacy_model(' '.join(tokens))\n",
    "    tokens = [t for t in tokens if not t.is_punct]\n",
    "    tokens = [str(t) for t in tokens if not t.is_space]\n",
    "    \n",
    "    tokens = [t for t in tokens if str(t)!=\"'s\"]\n",
    "    text = ' '.join(tokens)\n",
    "    seq = xtk.texts_to_sequences([text])\n",
    "    seq = pad_sequences(seq,maxlen=74,padding='post')\n",
    "    return seq.reshape((1,74))\n",
    "\n",
    "def seq2seq_prediction(in_seq,encoder_inf,decoder_inf):\n",
    "    e_out,st_h,st_c = encoder_inf.predict(in_seq)\n",
    "    tar_seq = np.zeros((1,1))\n",
    "    tar_seq[0,0] = ytk.word_index['<sos>']\n",
    "    stop = False\n",
    "    dec_seq = \"\"\n",
    "    \n",
    "    while not stop:\n",
    "        out_tok,pred_h,pred_c = decoder_inf.predict([tar_seq,e_out,st_h,st_c])\n",
    "        idx = np.argmax(out_tok[0,-1,:])\n",
    "        sampled_tok = ytk.index_word[idx]\n",
    "        \n",
    "        if sampled_tok != '<eos>' and len(dec_seq.split()) < 18: \n",
    "            dec_seq += \" \" + sampled_tok\n",
    "        \n",
    "        else:\n",
    "            stop = True\n",
    "        \n",
    "        tar_seq = np.zeros((1,1))\n",
    "        tar_seq[0,0] = idx\n",
    "        \n",
    "        st_h = pred_h\n",
    "        st_c = pred_c\n",
    "        \n",
    "    return dec_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a4cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 74)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, 74, 100)      3098000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_0 (LSTM)               [(None, 74, 200),    240800      ['encoder_embedding[0][0]']      \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " encoder_1 (LSTM)               [(None, 74, 200),    320800      ['encoder_0[0][0]',              \n",
      "                                 (None, 200),                     'encoder_0[0][1]',              \n",
      "                                 (None, 200)]                     'encoder_0[0][2]']              \n",
      "                                                                                                  \n",
      " encoder_2 (LSTM)               [(None, 74, 200),    320800      ['encoder_1[0][0]',              \n",
      "                                 (None, 200),                     'encoder_1[0][1]',              \n",
      "                                 (None, 200)]                     'encoder_1[0][2]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,980,400\n",
      "Trainable params: 3,980,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 100)    1354500     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 200),  240800      ['decoder_embedding[0][0]',      \n",
      "                                 (None, 200),                     'input_5[0][0]',                \n",
      "                                 (None, 200)]                     'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 74, 200)]    0           []                               \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, None, 200)    0           ['decoder_lstm[2][0]',           \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, None, 400)    0           ['attention_1[0][0]',            \n",
      "                                                                  'decoder_lstm[2][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 13545)  5431545     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,026,845\n",
      "Trainable params: 5,672,345\n",
      "Non-trainable params: 1,354,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#initialize class\n",
    "s2s = Seq2Seq()\n",
    "\n",
    "# initialize encoder and decoder inference models\n",
    "encoder_inf = s2s.encoder_inference_model(model)\n",
    "decoder_inf = s2s.decoder_inference_model(model)\n",
    "\n",
    "encoder_inf.summary()\n",
    "decoder_inf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f1d73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"news_summaries.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bd6504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC dismisses plea over illegal excavation, construction at Puri temple\n",
      "\n",
      " sc orders probe into tirumala temple shrine to be\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0,len(data)-1)\n",
    "print(actual[i])\n",
    "print()\n",
    "seq = create_input_seq(text[i])\n",
    "print(seq2seq_prediction(seq,encoder_inf,decoder_inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5216be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(df, num_pred=5):\n",
    "    for _ in range(num_pred):\n",
    "        i = random.randint(0,len(data)-1)\n",
    "        print(f\"Text : {df.text.loc[i]}\")\n",
    "        print(f\"Actual Summary : {df.headlines.loc[i]}\")\n",
    "        seq = create_input_seq(df.text.loc[i])\n",
    "        pred = seq2seq_prediction(seq, encoder_inf, decoder_inf).strip()\n",
    "        print(f\"Predicted Summary : {pred}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cab30a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text : A film on the life of environmentalist Dr Binish Desai, known as the 'Recycle Man of India', is under development. \"[It'll] be...world's first mainstream Bollywood movie which will revolve around a change maker's journey working towards eliminating the idea of waste,\" Desai said. The biopic will aim at promoting sustainability with a carbon-negative approach throughout its making, makers said.  \n",
      "Actual Summary : Film on India's Recycle Man Binish Desai in the works\n",
      "Predicted Summary : first film to be a star wars in india\n",
      "\n",
      "Text : A 13-year-old boy, Sai Sudhir Kawade, from Pune, climbed the Kala Patthar mountain in Nepal at an elevation of 5644.5 metres. Sai was the youngest mountaineer to participate in the Tenzing Hillary Everest Marathon. Reports said that 45 countries participated in the annual marathon. Sai unfurled a 175-feet Tricolour after climbing the peak.\n",
      "Actual Summary : 13-yr-old Pune boy climbs Kala Patthar in Nepal, unfurls Tricolour\n",
      "Predicted Summary : indian man sweeps 3 km marathon in himalayas\n",
      "\n",
      "Text : The Congress party on Sunday condoled the demise of singer and party leader Sidhu Moosewala, who was shot dead in an attack in Punjab's Mansa. \"The murder of Shri Sidhu Moose Wala, Congress candidate from Punjab & a talented musician, has come as a terrible shock to the Congress party & the entire nation,\" the party tweeted.\n",
      "Actual Summary : Congress condoles Sidhu Moosewala's demise, says 'the murder came as a terrible shock'\n",
      "Predicted Summary : congress leader shot dead in gujarat cong leader\n",
      "\n",
      "Text : At least 9 lakh Afghans lost their jobs since the Taliban came to power in Afghanistan following withdrawal of American forces, said US Special Inspector General for Afghanistan Reconstruction (SIGAR). Women's participation in the workforce is expected to shrink by 21% by mid-2022, said a report. Notably, the Taliban recently mandated women to cover their bodies completely in public.\n",
      "Actual Summary : 9 lakh Afghans lost their jobs since Taliban takeover: US body\n",
      "Predicted Summary : afghan children separated to us in afghanistan\n",
      "\n",
      "Text : Marathi actress Ketaki Chitale on Thursday filed a petition in the Bombay High Court challenging her arrest for allegedly sharing an offensive post on social media about NCP chief Sharad Pawar. The actress in her plea said that her arrest was not in accordance with the law and must be declared illegal by the HC. \n",
      "Actual Summary : Arrested for indecent post on Pawar, Marathi actress files plea in HC\n",
      "Predicted Summary : court rejects plea against haasan in film\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predictions(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc955d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
